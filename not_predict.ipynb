{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudo da composição das previsões do rating final\n",
    "\n",
    "O objetivo é realizar previsões para toda base gerando um rating unindo o contribuinte e posteriormente o igr gerado na regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processo iniciado\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import zipfile\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Processo iniciado\")\n",
    "\n",
    "# Define diretorios\n",
    "rootPath = os.getcwd()\n",
    "dataPath = os.path.join(rootPath, 'data')\n",
    "modelsPath = os.path.join(rootPath, 'models')\n",
    "env = os.path.join(rootPath, '.env')\n",
    "dotenv.load_dotenv(dotenv_path=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    region_name='us-east-1',\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACESS_KEY\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACESS_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados para previsões\n"
     ]
    }
   ],
   "source": [
    "print(\"Carregando dados para previsões\")\n",
    "\n",
    "# Prepara os dados para realizar as previsões\n",
    "\n",
    "zip_file = os.path.join(dataPath, 'estoque_da3.zip')\n",
    "z = zipfile.ZipFile(zip_file)\n",
    "\n",
    "\n",
    "def ler_bases_exportadas(nome_arquivo):\n",
    "    z.extract(nome_arquivo)\n",
    "    df = pd.read_csv(nome_arquivo, sep=',')\n",
    "    os.remove(nome_arquivo)\n",
    "    return df\n",
    "\n",
    "\n",
    "base_conjunta = ler_bases_exportadas('estoque-divida.csv')\n",
    "# base_parcelas = ler_bases_exportadas('parcelas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cda', 'tipo_divida', 'da_paga', 'da_aberto', 'id_contribuinte',\n",
       "       'atividade_principal', 'situacao', 'tipo_tributo', 'base', 'valor_tot',\n",
       "       'vlr_tributo', 'vlr_taxa', 'competencia_divida', 'inscricao_divida',\n",
       "       'arrecadacao_divida', 'ajuizamento_divida', 'terreno',\n",
       "       'cpf_cnpj_existe', 'protesto', 'ajuizamento', 'refis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_conjunta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicia transformação das variáveis sobre a dívida\n",
      "Processamento das variáveis sobre a dívida\n"
     ]
    }
   ],
   "source": [
    "print(\"Inicia transformação das variáveis sobre a dívida\")\n",
    "print(\"Processamento das variáveis sobre a dívida\")\n",
    "\n",
    "# Gera as variáveis de tempo\n",
    "base_conjunta['data_divida'] = pd.to_datetime(base_conjunta['inscricao_divida'], infer_datetime_format = True)\n",
    "base_conjunta['ano_inscricao_da'] = base_conjunta['data_divida'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona dados sobre a divida\n",
    "dados_divida = base_conjunta[\n",
    "    ['cda', 'id_contribuinte', 'da_aberto', 'valor_tot', 'vlr_tributo', 'vlr_taxa', 'da_paga', 'arrecadacao_divida',\n",
    "     'refis', 'ajuizamento_divida', 'atividade_principal', 'tipo_divida', 'ano_inscricao_da', 'protesto',\n",
    "     'ajuizamento', 'base']]\n",
    "dados_divida.dropna(subset=['id_contribuinte'], inplace=True)\n",
    "dados_divida['id_contribuinte'] = dados_divida['id_contribuinte'].astype(str)  # persistindo tipo de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a idade da dívida ativa\n",
    "dados_divida['ano_atual'] = date.today().year\n",
    "dados_divida['anos_idade_da'] = dados_divida['ano_atual'] - dados_divida['ano_inscricao_da']\n",
    "dados_divida = dados_divida.drop(columns=['ano_atual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeia colunas para nome mais adequados e filtra dataframe\n",
    "colunas_nome = {\n",
    "    'valor_tot': 'valor_total_da',\n",
    "}\n",
    "df_divida_ativa = dados_divida.rename(columns=colunas_nome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtem os dados de parcelamento das dívidas ativas\n",
    "\n",
    "# df_parcelas = base_parcelas[['cda', 'id_pessoa', 'tipo_divida', 'quantidade_reparcelamentos']]\n",
    "# df_parcelas.drop_duplicates(subset='cda', inplace=True)\n",
    "# df_parcelas.dropna(subset='cda', inplace=True)\n",
    "\n",
    "# df_divida_ativa = pd.merge(\n",
    "#         df_divida_ativa,    \n",
    "#         df_parcelas,    \n",
    "#         how='left',    \n",
    "#         left_on=['cda', 'tipo_divida', 'id_contribuinte'],    \n",
    "#         right_on=['cda', 'tipo_divida', 'id_pessoa'],    \n",
    "#         suffixes=('', '_PARC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento das variáveis sobre o contribuinte\n"
     ]
    }
   ],
   "source": [
    "print(\"Processamento das variáveis sobre o contribuinte\")\n",
    "\n",
    "# Cria conexão com o banco e prepara os dados\n",
    "\n",
    "def read_s3_files(bucket_name, folder_name, file_name):\n",
    "    file_key_aws = folder_name + file_name\n",
    "    obj = s3.Bucket(bucket_name).Object(file_key_aws).get()\n",
    "    df = pd.read_csv(obj['Body'], sep=';')\n",
    "    return df\n",
    "\n",
    "dados_contribuinte = read_s3_files(bucket_name=os.getenv(\"S3_BUCKET_NAME\"), folder_name=os.getenv(\"S3_FOLDER_NAME\"),\n",
    "                                   file_name='feature_store_contribuinte_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza o merge dos dados da dívida com os dados do contribuinte\n",
    "\n",
    "dados_totais = pd.merge(\n",
    "    left=df_divida_ativa,\n",
    "    right=dados_contribuinte,\n",
    "    left_on='id_contribuinte',\n",
    "    right_on='id_pessoa',\n",
    "    how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cda', 'id_contribuinte', 'da_aberto', 'valor_total_da', 'vlr_tributo',\n",
       "       'vlr_taxa', 'da_paga', 'arrecadacao_divida', 'refis',\n",
       "       'ajuizamento_divida', 'atividade_principal', 'tipo_divida',\n",
       "       'ano_inscricao_da', 'protesto', 'ajuizamento', 'base', 'anos_idade_da',\n",
       "       'id_pessoa', 'situacao', 'cpf_cnpj_existe', 'edificacao',\n",
       "       'qtd_notas_2anos', 'situacao_ativa', 'status_situacao', 'deb_totais',\n",
       "       'deb_pagos', 'valor_tot', 'valor_pago', 'frequencia_da_pessoa',\n",
       "       'total_debitos_pessoa', 'debitos_pagos_pessoa', 'valor_total_pessoa',\n",
       "       'valor_pago_pessoa', 'historico_pagamento_em_qtd',\n",
       "       'historico_pagamento_em_valor', 'class_contribuinte',\n",
       "       'class_contribuinte_nome', 'class_contribuinte_peso'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_totais.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dados_totais[\n",
    "    ['cda', 'id_contribuinte', 'da_aberto', 'da_paga', 'arrecadacao_divida', 'tipo_divida', 'valor_total_da',\n",
    "     'vlr_tributo', 'vlr_taxa', 'ano_inscricao_da', 'protesto', 'ajuizamento', 'refis', 'ajuizamento_divida',\n",
    "    'atividade_principal', 'base', 'anos_idade_da', 'cpf_cnpj_existe', 'edificacao', #'quantidade_reparcelamentos', \n",
    "    'qtd_notas_2anos',\n",
    "     'situacao', 'status_situacao', 'frequencia_da_pessoa', 'historico_pagamento_em_qtd','historico_pagamento_em_valor',\n",
    "     'class_contribuinte', 'class_contribuinte_nome', 'class_contribuinte_peso']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando pesos dos contribuintes, foi dado ao primeira dívida o mesmo peso do bom pagador, isso procede?\n",
    "df.loc[df['frequencia_da_pessoa'] <= 1, 'class_contribuinte_nome'] == 'PRIMEIRA DIVIDA'\n",
    "df.loc[df['class_contribuinte_nome'] == 'PRIMEIRA DIVIDA', 'class_contribuinte_peso'] == 4.70957\n",
    "\n",
    "df['class_contribuinte_nome'] = df['class_contribuinte_nome'].fillna('PIOR PAGADOR')\n",
    "df.loc[df['class_contribuinte_nome'] == 'PIOR PAGADOR', 'class_contribuinte_peso'] == -1.59910\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparação do pipeline de previsões\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparação do pipeline de previsões\")\n",
    "# Filtra os dados que precisamos para previsão\n",
    "df_feature_store = df[['valor_total_da', 'anos_idade_da', #'quantidade_reparcelamentos',\n",
    "                       'frequencia_da_pessoa', 'historico_pagamento_em_qtd', 'status_situacao',\n",
    "                       'historico_pagamento_em_valor', 'class_contribuinte_peso']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza os dados para previsão utilizando o StandardScaler\n",
    "normalizador = RobustScaler()\n",
    "normalizador.fit(df_feature_store)\n",
    "dados_normalizados = normalizador.fit_transform(df_feature_store)\n",
    "\n",
    "colunas = list(normalizador.get_feature_names_out())\n",
    "df_normalizado = pd.DataFrame(dados_normalizados, columns=colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carrega o modelo e realiza a previsão do Índice Geral de Recuperação (IGR)\n"
     ]
    }
   ],
   "source": [
    "print(\"Carrega o modelo e realiza a previsão do Índice Geral de Recuperação (IGR)\")\n",
    "\n",
    "\n",
    "def abre_modelo(nome_modelo, path_modelo, zip_name=None):\n",
    "    if zip_name:\n",
    "        zip_file = os.path.join(path_modelo, zip_name)\n",
    "        z = zipfile.ZipFile(zip_file)\n",
    "        z.extract(nome_modelo)\n",
    "    else:\n",
    "        nome_modelo = os.path.join(path_modelo, nome_modelo)\n",
    "\n",
    "    modelo = pickle.load(open(nome_modelo, 'rb'))\n",
    "    return modelo\n",
    "\n",
    "\n",
    "model_predict_igr = abre_modelo(\"modeloDA-igr-divida-v2.pkl\", modelsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Início do processo de classificação do rating da dívida parametrizando junto a classificação do contribuinte\n"
     ]
    }
   ],
   "source": [
    "# Momento onde classificamos o rating final com base em nossos Outputs \n",
    "\n",
    "previsoes = model_predict_igr.predict(df_normalizado)\n",
    "df['igr'] = previsoes\n",
    "\n",
    "df.loc[df['status_situacao'] == 0, 'igr'] = 0\n",
    "df.loc[df['anos_idade_da'] >= 15, 'igr'] = 0\n",
    "\n",
    "print(\"Início do processo de classificação do rating da dívida parametrizando junto a classificação do contribuinte\")\n",
    "\n",
    "def make_rating_divida(dataframe):\n",
    "    dataframe.loc[dataframe['igr'] == 0, 'rating_divida'] = 'BAIXISSIMA'\n",
    "\n",
    "    # Melhor Pagador\n",
    "    dataframe.loc[(dataframe['rating_divida'].isnull()) & (dataframe['class_contribuinte'] == 3), 'rating_divida'] = 'ALTISSIMA'\n",
    "\n",
    "    # Pior Pagador\n",
    "    dataframe.loc[(dataframe['class_contribuinte'] == 1) & (dataframe['igr'] != 0), 'rating_divida'] = 'BAIXA'\n",
    "\n",
    "    # dataframe.loc[(dataframe['class_contribuinte'] == 3) & (dataframe['igr'] >= 0.5), 'rating_divida'] = 'ALTISSIMA'\n",
    "    # dataframe.loc[(dataframe['class_contribuinte'] == 3) & (dataframe['igr'] < 0.5) & (dataframe['igr'] >= 0.1), 'rating_divida'] = 'ALTA'\n",
    "    # dataframe.loc[(dataframe['class_contribuinte'] == 3) & (dataframe['igr'] < 0.1) & (dataframe['igr'] != 0), 'rating_divida'] = 'MEDIA'\n",
    "\n",
    "    # Pagador intermediario\n",
    "    dataframe.loc[(dataframe['class_contribuinte'] == 0) & (dataframe['igr'] >= 0.5), 'rating_divida'] = 'ALTA'\n",
    "    dataframe.loc[(dataframe['class_contribuinte'] == 0) & (dataframe['igr'] < 0.5) & (dataframe['igr'] >= 0.05), 'rating_divida'] = 'MEDIA'\n",
    "    dataframe.loc[(dataframe['class_contribuinte'] == 0) & (dataframe['igr'] < 0.1) & (dataframe['igr'] != 0), 'rating_divida'] = 'BAIXA'\n",
    "\n",
    "    # Bom pagador\n",
    "    dataframe.loc[(dataframe['class_contribuinte'] == 2) & (dataframe['igr'] >= 0.5), 'rating_divida'] = 'ALTISSIMA'\n",
    "    dataframe.loc[(dataframe['class_contribuinte'] == 2) & (dataframe['igr'] < 0.5) & (dataframe['igr'] >= 0.05), 'rating_divida'] = 'ALTA'\n",
    "    dataframe.loc[(dataframe['class_contribuinte'] == 2) & (dataframe['igr'] < 0.05) & (dataframe['igr'] != 0), 'rating_divida'] = 'MEDIA'\n",
    "\n",
    "    # Primeira dívida\n",
    "    dataframe.loc[(dataframe['class_contribuinte'] == 4) & (dataframe['igr'] >= 0.3), 'rating_divida'] = 'ALTA'\n",
    "    dataframe.loc[(dataframe['class_contribuinte'] == 4) & (dataframe['igr'] < 0.3) & dataframe['igr'] >= 0.1, 'rating_divida'] = 'MEDIA'\n",
    "    dataframe.loc[(dataframe['class_contribuinte'] == 4) & (dataframe['igr'] < 0.1) & (dataframe['igr'] != 0), 'rating_divida'] = 'BAIXA'\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "df = make_rating_divida(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicia a conexão com S3 para inscrição dos dados com as previsões\n",
      "Upload de dados efetuados no s3\n",
      "Processo finalizado\n",
      "Arquivo disponível para download e análise\n"
     ]
    }
   ],
   "source": [
    "print(\"Inicia a conexão com S3 para inscrição dos dados com as previsões\")\n",
    "\n",
    "# Cria conexão ao s3 e preenche a tabela com os dados\n",
    "\n",
    "def up_s3_files(dataframe, bucket_name, folder_name, file_name):\n",
    "    csv_buffer = BytesIO()\n",
    "    dataframe.to_csv(csv_buffer, sep=';', index=False)\n",
    "    file_key_aws = folder_name + file_name\n",
    "    s3.Object(bucket_name, file_key_aws).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "\n",
    "up_s3_files(dataframe=df,\n",
    "            bucket_name=os.getenv(\"S3_BUCKET_NAME\"),\n",
    "            folder_name=os.getenv(\"S3_FOLDER_NAME\"),\n",
    "            file_name='previsoes_igr_status_situacao_sem_parcelas_com_cpf.csv')\n",
    "\n",
    "print(\"Upload de dados efetuados no s3\")\n",
    "print(\"Processo finalizado\")\n",
    "print(\"Arquivo disponível para download e análise\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-recife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
